{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "0nbI5DtDGw-i"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TnJztDZGw-n"
   },
   "source": [
    "# RNN を使ったテキスト分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "z682XYsrjkY9"
   },
   "outputs": [],
   "source": [
    "# !pip install -q tf-nightly\n",
    "# import tensorflow_datasets as tfds\n",
    "# !pip3 list | grep tensorflow\n",
    "# import tensorflow as tf\n",
    "\n",
    "# !pip3 install sentencepiece\n",
    "import sentencepiece as spm\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Mp1Z7P9pYRSK"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_graphs(history, metric):\n",
    "#   plt.plot(history.history[metric])\n",
    "#   plt.plot(history.history['val_'+metric], '')\n",
    "#   plt.xlabel(\"Epochs\")\n",
    "#   plt.ylabel(metric)\n",
    "#   plt.legend([metric, 'val_'+metric])\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRmMubr0jrE2"
   },
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRmMubr0jrE2"
   },
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>&lt;instruction/&gt;</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(symbol-sentence)*2</td>\n",
       "      <td>&lt;instruction&gt;次の問い(問１・問２)において，下線部(a)・(b)の単語のアクセ...</td>\n",
       "      <td>&lt;label&gt;&lt;label&gt;問１&lt;label/&gt;問１&lt;label/&gt;&lt;ansColumn&gt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(symbol-sentence)*2</td>\n",
       "      <td>&lt;instruction&gt;次の問い(問１・問２)において，下線部(a)・(b)の単語のアクセ...</td>\n",
       "      <td>&lt;label&gt;&lt;label&gt;問２&lt;label/&gt;問２&lt;label/&gt;&lt;ansColumn&gt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sentence</td>\n",
       "      <td>&lt;instruction&gt;次の会話の下線部(1)～(4)について，それぞれ以下の問い(問１～...</td>\n",
       "      <td>&lt;label&gt;&lt;label&gt;問１&lt;label/&gt;問１&lt;label/&gt;&lt;ansColumn&gt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>sentence</td>\n",
       "      <td>&lt;instruction&gt;次の会話の下線部(1)～(4)について，それぞれ以下の問い(問１～...</td>\n",
       "      <td>&lt;label&gt;&lt;label&gt;問２&lt;label/&gt;問２&lt;label/&gt;&lt;ansColumn&gt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>sentence</td>\n",
       "      <td>&lt;instruction&gt;次の会話の下線部(1)～(4)について，それぞれ以下の問い(問１～...</td>\n",
       "      <td>&lt;label&gt;&lt;label&gt;問３&lt;label/&gt;問３&lt;label/&gt;&lt;ansColumn&gt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>978</td>\n",
       "      <td>sentence</td>\n",
       "      <td>&lt;instruction&gt;次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なもの...</td>\n",
       "      <td>&lt;label&gt;&lt;label&gt;問２&lt;label/&gt;問２&lt;label/&gt;&lt;data&gt;&lt;ref&gt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>979</td>\n",
       "      <td>sentence</td>\n",
       "      <td>&lt;instruction&gt;次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なもの...</td>\n",
       "      <td>&lt;label&gt;&lt;label&gt;問３&lt;label/&gt;問３&lt;label/&gt;&lt;data&gt;&lt;ref&gt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>980</td>\n",
       "      <td>sentence</td>\n",
       "      <td>&lt;instruction&gt;次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なもの...</td>\n",
       "      <td>&lt;label&gt;&lt;label&gt;問４&lt;label/&gt;問４&lt;label/&gt;&lt;data&gt;&lt;ref&gt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>981</td>\n",
       "      <td>sentence</td>\n",
       "      <td>&lt;instruction&gt;次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なもの...</td>\n",
       "      <td>&lt;label&gt;&lt;label&gt;問５&lt;label/&gt;問５&lt;label/&gt;&lt;data&gt;&lt;data&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>982</td>\n",
       "      <td>sentence</td>\n",
       "      <td>&lt;instruction&gt;次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なもの...</td>\n",
       "      <td>&lt;label&gt;&lt;label&gt;Ｂ&lt;label/&gt;Ｂ&lt;label/&gt;&lt;instruction&gt;&lt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>983 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0          answer_type  \\\n",
       "0             0  (symbol-sentence)*2   \n",
       "1             1  (symbol-sentence)*2   \n",
       "2             2             sentence   \n",
       "3             3             sentence   \n",
       "4             4             sentence   \n",
       "..          ...                  ...   \n",
       "978         978             sentence   \n",
       "979         979             sentence   \n",
       "980         980             sentence   \n",
       "981         981             sentence   \n",
       "982         982             sentence   \n",
       "\n",
       "                                        <instruction/>  \\\n",
       "0    <instruction>次の問い(問１・問２)において，下線部(a)・(b)の単語のアクセ...   \n",
       "1    <instruction>次の問い(問１・問２)において，下線部(a)・(b)の単語のアクセ...   \n",
       "2    <instruction>次の会話の下線部(1)～(4)について，それぞれ以下の問い(問１～...   \n",
       "3    <instruction>次の会話の下線部(1)～(4)について，それぞれ以下の問い(問１～...   \n",
       "4    <instruction>次の会話の下線部(1)～(4)について，それぞれ以下の問い(問１～...   \n",
       "..                                                 ...   \n",
       "978  <instruction>次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なもの...   \n",
       "979  <instruction>次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なもの...   \n",
       "980  <instruction>次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なもの...   \n",
       "981  <instruction>次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なもの...   \n",
       "982  <instruction>次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なもの...   \n",
       "\n",
       "                                              contents  \n",
       "0    <label><label>問１<label/>問１<label/><ansColumn><...  \n",
       "1    <label><label>問２<label/>問２<label/><ansColumn><...  \n",
       "2    <label><label>問１<label/>問１<label/><ansColumn><...  \n",
       "3    <label><label>問２<label/>問２<label/><ansColumn><...  \n",
       "4    <label><label>問３<label/>問３<label/><ansColumn><...  \n",
       "..                                                 ...  \n",
       "978  <label><label>問２<label/>問２<label/><data><ref><...  \n",
       "979  <label><label>問３<label/>問３<label/><data><ref><...  \n",
       "980  <label><label>問４<label/>問４<label/><data><ref><...  \n",
       "981  <label><label>問５<label/>問５<label/><data><data>...  \n",
       "982  <label><label>Ｂ<label/>Ｂ<label/><instruction><...  \n",
       "\n",
       "[983 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbj_name = 'Eigo'\n",
    "attr_name = 'answer_type'\n",
    "\n",
    "attr_csv_path = f'../{sbj_name}_{attr_name}_ds.tsv'\n",
    "df = pd.read_csv(attr_csv_path, delimiter='\\t')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRmMubr0jrE2"
   },
   "source": [
    "### Tokenize\n",
    "SentencePiece を使用。\n",
    "- タグ あり／なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SHRwRoP2nVHX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>&lt;instruction/&gt;</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>893</td>\n",
       "      <td>sentence</td>\n",
       "      <td>&lt;instruction&gt;次の問い（問１～４）において，第一アクセント（第一強勢）の位置がほ...</td>\n",
       "      <td>&lt;label&gt;&lt;label&gt;問２&lt;label/&gt;問２&lt;label/&gt;&lt;ansColumn&gt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>158</td>\n",
       "      <td>sentence</td>\n",
       "      <td>&lt;instruction&gt;次の広告に関する以下の問い(問１～３)を読み， 39 ～ 41 に...</td>\n",
       "      <td>&lt;label&gt;&lt;label&gt;問２&lt;label/&gt;問２&lt;label/&gt;&lt;data&gt;&lt;ansCo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>154</td>\n",
       "      <td>sentence</td>\n",
       "      <td>&lt;instruction&gt;次の英文は，体育の授業時間数について，クラスで行われたディスカッシ...</td>\n",
       "      <td>&lt;label&gt;&lt;label&gt;Ｃ&lt;label/&gt;Ｃ&lt;label/&gt;&lt;instruction&gt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>sentence</td>\n",
       "      <td>&lt;instruction&gt;次の問い(問１～５)に対する答えとして最も適当なものを，それぞれ以...</td>\n",
       "      <td>&lt;label&gt;&lt;label&gt;Ｂ&lt;label/&gt;Ｂ&lt;label/&gt;&lt;instruction&gt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>793</td>\n",
       "      <td>sentence</td>\n",
       "      <td>&lt;instruction&gt;次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なもの...</td>\n",
       "      <td>&lt;label&gt;&lt;label&gt;問５&lt;label/&gt;問５&lt;label/&gt;&lt;data&gt;&lt;data&gt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 answer_type  \\\n",
       "893         893    sentence   \n",
       "158         158    sentence   \n",
       "154         154    sentence   \n",
       "40           40    sentence   \n",
       "793         793    sentence   \n",
       "\n",
       "                                        <instruction/>  \\\n",
       "893  <instruction>次の問い（問１～４）において，第一アクセント（第一強勢）の位置がほ...   \n",
       "158  <instruction>次の広告に関する以下の問い(問１～３)を読み， 39 ～ 41 に...   \n",
       "154  <instruction>次の英文は，体育の授業時間数について，クラスで行われたディスカッシ...   \n",
       "40   <instruction>次の問い(問１～５)に対する答えとして最も適当なものを，それぞれ以...   \n",
       "793  <instruction>次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なもの...   \n",
       "\n",
       "                                              contents  \n",
       "893  <label><label>問２<label/>問２<label/><ansColumn><...  \n",
       "158  <label><label>問２<label/>問２<label/><data><ansCo...  \n",
       "154  <label><label>Ｃ<label/>Ｃ<label/><instruction><...  \n",
       "40   <label><label>Ｂ<label/>Ｂ<label/><instruction><...  \n",
       "793  <label><label>問５<label/>問５<label/><data><data>...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_examples, test_examples = train_test_split(\n",
    "                                    df, test_size=0.2, random_state=0)\n",
    "train_examples.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<instruction>次の問い(問１～10)の 7 ～ 16 に入れるのに最も適当なものを，それぞれ以下の①～④のうちから一つずつ選べ。<instruction/>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp = df[['<instruction/>', 'contents']]\n",
    "df_tmp['<instruction/>'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_dir = 'model/SentencePiece'\n",
    "os.makedirs(m_dir, exist_ok=True)\n",
    "df.to_csv(f'{m_dir}/tmp.txt', sep='\\t')\n",
    "\n",
    "# arg_str = '--input={m_dir}/tmp.txt --model_prefix={m_dir}/m_user ' + '--user_defined_symbols=<sep>,<cls>' + ',<ansColumn/>,<label>' + ' --vocab_size=2000'\n",
    "# spm.SentencePieceTrainer.train(arg_str)\n",
    "\n",
    "spm.SentencePieceTrainer.train(f'--input={m_dir}/tmp.txt --model_prefix={m_dir}/m  --user_defined_symbols=<sep>,<cls>,<pad>   --vocab_size=2000')\n",
    "sp = spm.SentencePieceProcessor()  # model_file='SentencePiece/test_model.model'\n",
    "\n",
    "sp.load(f'{m_dir}/m.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', '次の', '問', 'い', '(', '問', '1～3)', 'の会話の', '▁17', '▁～', '▁19', '▁に入れる', 'の', 'に', '最も適当な', 'ものを', ',', 'それぞれ以下の', '1～4', 'のうちから一つ', 'ず', 'つ選べ', '。']\n",
      "[39, 49, 29, 52, 56, 29, 132, 323, 387, 153, 479, 144, 55, 124, 128, 94, 34, 173, 83, 90, 89, 86, 58]\n",
      "次の問い(問1～3)の会話の 17 ～ 19 に入れるのに最も適当なものを,それぞれ以下の1～4のうちから一つずつ選べ。\n"
     ]
    }
   ],
   "source": [
    "# encode: text => id\n",
    "tokenized_tokens =  sp.encode_as_pieces('次の問い(問１～３)の会話の 17 ～ 19 に入れるのに最も適当なものを，それぞれ以下の①～④のうちから一つずつ選べ。\t')\n",
    "print(tokenized_tokens)\n",
    "\n",
    "tokenized_ids = sp.encode_as_ids('次の問い(問１～３)の会話の 17 ～ 19 に入れるのに最も適当なものを，それぞれ以下の①～④のうちから一つずつ選べ。\t')\n",
    "print(tokenized_ids)\n",
    "\n",
    "decoded_text = sp.decode(tokenized_ids)\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<label><label>問２<label/>問２<label/><data><blank><blank><blank/><blank/><ansColumn><ansColumn>22<ansColumn/>22<ansColumn/><blank><blank><blank/><blank/><ansColumn><ansColumn>23<ansColumn/>23<ansColumn/><blank><blank><blank/><blank/><data><blank><blank><blank/><blank/><ansColumn><ansColumn>22<ansColumn/>22<ansColumn/><blank><blank><blank/><blank/><ansColumn><ansColumn>23<ansColumn/>23<ansColumn/><blank><blank><blank/><blank/>New information about diet<data/>New information about diet<data/><choices><choice><cNum><cNum>①<cNum/>①<cNum/><choice><cNum><cNum>①<cNum/>①<cNum/><choice/><choice/><choice><cNum><cNum>②<cNum/>②<cNum/><choice><cNum><cNum>②<cNum/>②<cNum/><choice/><choice/><choice><cNum><cNum>③<cNum/>③<cNum/><choice><cNum><cNum>③<cNum/>③<cNum/><choice/><choice/><choice><cNum><cNum>④<cNum/>④<cNum/><choice><cNum><cNum>④<cNum/>④<cNum/><choice/><choice/><choice><cNum><cNum>⑤<cNum/>⑤<cNum/><choice><cNum><cNum>⑤<cNum/>⑤<cNum/><choice/><choice/><choices><choice><cNum><cNum>①<cNum/>①<cNum/><choice><cNum><cNum>①<cNum/>①<cNum/><choice/><choice/><choice><cNum><cNum>②<cNum/>②<cNum/><choice><cNum><cNum>②<cNum/>②<cNum/><choice/><choice/><choice><cNum><cNum>③<cNum/>③<cNum/><choice><cNum><cNum>③<cNum/>③<cNum/><choice/><choice/><choice><cNum><cNum>④<cNum/>④<cNum/><choice><cNum><cNum>④<cNum/>④<cNum/><choice/><choice/><choice><cNum><cNum>⑤<cNum/>⑤<cNum/><choice><cNum><cNum>⑤<cNum/>⑤<cNum/><choice/><choice/><choices/><choices/><question><label><label>問２<label/>問２<label/><data><blank><blank><blank/><blank/><ansColumn><ansColumn>22<ansColumn/>22<ansColumn/><blank><blank><blank/><blank/><ansColumn><ansColumn>23<ansColumn/>23<ansColumn/><blank><blank><blank/><blank/><data><blank><blank><blank/><blank/><ansColumn><ansColumn>22<ansColumn/>22<ansColumn/><blank><blank><blank/><blank/><ansColumn><ansColumn>23<ansColumn/>23<ansColumn/><blank><blank><blank/><blank/>New information about diet<data/>New information about diet<data/><choices><choice><cNum><cNum>①<cNum/>①<cNum/><choice><cNum><cNum>①<cNum/>①<cNum/><choice/><choice/><choice><cNum><cNum>②<cNum/>②<cNum/><choice><cNum><cNum>②<cNum/>②<cNum/><choice/><choice/><choice><cNum><cNum>③<cNum/>③<cNum/><choice><cNum><cNum>③<cNum/>③<cNum/><choice/><choice/><choice><cNum><cNum>④<cNum/>④<cNum/><choice><cNum><cNum>④<cNum/>④<cNum/><choice/><choice/><choice><cNum><cNum>⑤<cNum/>⑤<cNum/><choice><cNum><cNum>⑤<cNum/>⑤<cNum/><choice/><choice/><choices><choice><cNum><cNum>①<cNum/>①<cNum/><choice><cNum><cNum>①<cNum/>①<cNum/><choice/><choice/><choice><cNum><cNum>②<cNum/>②<cNum/><choice><cNum><cNum>②<cNum/>②<cNum/><choice/><choice/><choice><cNum><cNum>③<cNum/>③<cNum/><choice><cNum><cNum>③<cNum/>③<cNum/><choice/><choice/><choice><cNum><cNum>④<cNum/>④<cNum/><choice><cNum><cNum>④<cNum/>④<cNum/><choice/><choice/><choice><cNum><cNum>⑤<cNum/>⑤<cNum/><choice><cNum><cNum>⑤<cNum/>⑤<cNum/><choice/><choice/><choices/><choices/><question/> ['▁<', 'label', '><', 'label', '>', '問', '2<', 'label', '/>', '問', '2<', 'label', '/><', 'data', '><', 'blank', '><', 'blank', '><', 'blank', '/><', 'blank', '/><', 'ansColumn', '><', 'ansColumn', '>22', '<', 'ansColumn', '/>22', '<', 'ansColumn', '/><', 'blank', '><', 'blank', '><', 'blank', '/><', 'blank', '/><', 'ansColumn', '><', 'ansColumn', '>23<', 'ansColumn', '/>23<', 'ansColumn', '/><', 'blank', '><', 'blank', '><', 'blank', '/><', 'blank', '/><', 'data', '><', 'blank', '><', 'blank', '><', 'blank', '/><', 'blank', '/><', 'ansColumn', '><', 'ansColumn', '>22', '<', 'ansColumn', '/>22', '<', 'ansColumn', '/><', 'blank', '><', 'blank', '><', 'blank', '/><', 'blank', '/><', 'ansColumn', '><', 'ansColumn', '>23<', 'ansColumn', '/>23<', 'ansColumn', '/><', 'blank', '><', 'blank', '><', 'blank', '/><', 'blank', '/>', 'New', '▁information', '▁about', '▁di', 'e', 't', '<', 'data', '/>', 'New', '▁information', '▁about', '▁di', 'e', 't', '<', 'data', '/><', 'choices', '><', 'choice', '><', 'cNum', '><', 'cNum', '>1<', 'cNum', '/>1<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>1<', 'cNum', '/>1<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>2<', 'cNum', '/>2<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>2<', 'cNum', '/>2<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>3<', 'cNum', '/>3<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>3<', 'cNum', '/>3<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>4<', 'cNum', '/>4<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>4<', 'cNum', '/>4<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>5<', 'cNum', '/>5<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>5<', 'cNum', '/>5<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choices', '><', 'choice', '><', 'cNum', '><', 'cNum', '>1<', 'cNum', '/>1<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>1<', 'cNum', '/>1<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>2<', 'cNum', '/>2<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>2<', 'cNum', '/>2<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>3<', 'cNum', '/>3<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>3<', 'cNum', '/>3<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>4<', 'cNum', '/>4<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>4<', 'cNum', '/>4<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>5<', 'cNum', '/>5<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>5<', 'cNum', '/>5<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choices', '/><', 'choices', '/><', 'question', '><', 'label', '><', 'label', '>', '問', '2<', 'label', '/>', '問', '2<', 'label', '/><', 'data', '><', 'blank', '><', 'blank', '><', 'blank', '/><', 'blank', '/><', 'ansColumn', '><', 'ansColumn', '>22', '<', 'ansColumn', '/>22', '<', 'ansColumn', '/><', 'blank', '><', 'blank', '><', 'blank', '/><', 'blank', '/><', 'ansColumn', '><', 'ansColumn', '>23<', 'ansColumn', '/>23<', 'ansColumn', '/><', 'blank', '><', 'blank', '><', 'blank', '/><', 'blank', '/><', 'data', '><', 'blank', '><', 'blank', '><', 'blank', '/><', 'blank', '/><', 'ansColumn', '><', 'ansColumn', '>22', '<', 'ansColumn', '/>22', '<', 'ansColumn', '/><', 'blank', '><', 'blank', '><', 'blank', '/><', 'blank', '/><', 'ansColumn', '><', 'ansColumn', '>23<', 'ansColumn', '/>23<', 'ansColumn', '/><', 'blank', '><', 'blank', '><', 'blank', '/><', 'blank', '/>', 'New', '▁information', '▁about', '▁di', 'e', 't', '<', 'data', '/>', 'New', '▁information', '▁about', '▁di', 'e', 't', '<', 'data', '/><', 'choices', '><', 'choice', '><', 'cNum', '><', 'cNum', '>1<', 'cNum', '/>1<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>1<', 'cNum', '/>1<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>2<', 'cNum', '/>2<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>2<', 'cNum', '/>2<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>3<', 'cNum', '/>3<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>3<', 'cNum', '/>3<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>4<', 'cNum', '/>4<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>4<', 'cNum', '/>4<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>5<', 'cNum', '/>5<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>5<', 'cNum', '/>5<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choices', '><', 'choice', '><', 'cNum', '><', 'cNum', '>1<', 'cNum', '/>1<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>1<', 'cNum', '/>1<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>2<', 'cNum', '/>2<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>2<', 'cNum', '/>2<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>3<', 'cNum', '/>3<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>3<', 'cNum', '/>3<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>4<', 'cNum', '/>4<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>4<', 'cNum', '/>4<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>5<', 'cNum', '/>5<', 'cNum', '/><', 'choice', '><', 'cNum', '><', 'cNum', '>5<', 'cNum', '/>5<', 'cNum', '/><', 'choice', '/><', 'choice', '/><', 'choices', '/><', 'choices', '/><', 'question', '/>']\n"
     ]
    }
   ],
   "source": [
    "example_content = df_tmp['contents'][20]\n",
    "print(example_content, sp.encode_as_pieces(example_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "MDVc6UGO5Dh6"
   },
   "outputs": [],
   "source": [
    "# for index in encoded_string:\n",
    "#   print('{} ----> {}'.format(index, encoder.decode([index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlYWqhTVlUyQ"
   },
   "source": [
    "## 訓練用データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "VznrltNOnUc5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-f87b331a5b30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mword2index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"<pad>\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mwakati\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_wakati\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwakati\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "word2index = {}\n",
    "# 系列を揃えるためのパディング文字列<pad>を追加\n",
    "# パディング文字列のIDは0とする\n",
    "word2index.update({\"<pad>\":0})\n",
    "\n",
    "for instruction in df['<instruction/>']:\n",
    "    tokens = sp.encode_as_pieces(instruction)\n",
    "    for word in tokens:\n",
    "        if word in word2index: continue\n",
    "        word2index[word] = len(word2index)\n",
    "print(\"vocab size : \", len(word2index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fv2DVb2m4Opl"
   },
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8lgLRE0z4Opm"
   },
   "outputs": [],
   "source": [
    "## 系列の長さを揃えてバッチでまとめる\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "cat2index = {}\n",
    "for cat in categories:\n",
    "    if cat in cat2index: continue\n",
    "    cat2index[cat] = len(cat2index)\n",
    "\n",
    "def sentence2index(sentence):\n",
    "    wakati = make_wakati(sentence)\n",
    "    return [word2index[w] for w in wakati]\n",
    "\n",
    "def category2index(cat):\n",
    "    return [cat2index[cat]]\n",
    "\n",
    "index_datasets_title_tmp = []\n",
    "index_datasets_category = []\n",
    "\n",
    "# 系列の長さの最大値を取得。この長さに他の系列の長さをあわせる\n",
    "max_len = 0\n",
    "for title, category in zip(datasets[\"title\"], datasets[\"category\"]):\n",
    "  index_title = sentence2index(title)\n",
    "  index_category = category2index(category)\n",
    "  index_datasets_title_tmp.append(index_title)\n",
    "  index_datasets_category.append(index_category)\n",
    "  if max_len < len(index_title):\n",
    "    max_len = len(index_title)\n",
    "\n",
    "# 系列の長さを揃えるために短い系列にパディングを追加\n",
    "# 後ろパディングだと正しく学習できなかったので、前パディング\n",
    "index_datasets_title = []\n",
    "for title in index_datasets_title_tmp:\n",
    "  for i in range(max_len - len(title)):\n",
    "    title.insert(0, 0) # 前パディング\n",
    "#     title.append(0)　# 後ろパディング\n",
    "  index_datasets_title.append(title)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(index_datasets_title, index_datasets_category, train_size=0.7)\n",
    "\n",
    "# データをバッチでまとめるための関数\n",
    "def train2batch(title, category, batch_size=100):\n",
    "  title_batch = []\n",
    "  category_batch = []\n",
    "  title_shuffle, category_shuffle = shuffle(title, category)\n",
    "  for i in range(0, len(title), batch_size):\n",
    "    title_batch.append(title_shuffle[i:i+batch_size])\n",
    "    category_batch.append(category_shuffle[i:i+batch_size])\n",
    "  return title_batch, category_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjUqGVBxGw-t"
   },
   "source": [
    "## モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LwfoBkmRYcP3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-863e4d760db0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = tf.keras.Sequential([\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # <pad>の単語IDが0なので、padding_idx=0としている\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        # batch_first=Trueが大事！\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        #embeds.size() = (batch_size × len(sentence) × embedding_dim)\n",
    "        _, lstm_out = self.lstm(embeds)\n",
    "        # lstm_out[0].size() = (1 × batch_size × hidden_dim)\n",
    "        tag_space = self.hidden2tag(lstm_out[0])\n",
    "        # tag_space.size() = (1 × batch_size × tagset_size)\n",
    "\n",
    "        # (batch_size × tagset_size)にするためにsqueeze()する\n",
    "        tag_scores = self.softmax(tag_space.squeeze())\n",
    "        # tag_scores.size() = (batch_size × tagset_size)\n",
    "\n",
    "        return tag_scores\n",
    "\n",
    "# 単語の埋め込み次元数上げた。精度がそこそこアップ！ハイパーパラメータのチューニング大事。\n",
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 128\n",
    "VOCAB_SIZE = len(word2index)\n",
    "TAG_SIZE = len(categories)\n",
    "# to(device)でモデルがGPU対応する\n",
    "model = LSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TAG_SIZE).to(device)\n",
    "loss_function = nn.NLLLoss()\n",
    "# SGDからAdamに変更。特に意味はなし\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIwH3nto596k"
   },
   "source": [
    "## モデルの訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.PaddedBatchDataset'>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.PaddedBatchDataset'>\n"
     ]
    }
   ],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # <pad>の単語IDが0なので、padding_idx=0としている\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        # batch_first=Trueが大事！\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        #embeds.size() = (batch_size × len(sentence) × embedding_dim)\n",
    "        _, lstm_out = self.lstm(embeds)\n",
    "        # lstm_out[0].size() = (1 × batch_size × hidden_dim)\n",
    "        tag_space = self.hidden2tag(lstm_out[0])\n",
    "        # tag_space.size() = (1 × batch_size × tagset_size)\n",
    "\n",
    "        # (batch_size × tagset_size)にするためにsqueeze()する\n",
    "        tag_scores = self.softmax(tag_space.squeeze())\n",
    "        # tag_scores.size() = (batch_size × tagset_size)\n",
    "\n",
    "        return tag_scores\n",
    "\n",
    "# 単語の埋め込み次元数上げた。精度がそこそこアップ！ハイパーパラメータのチューニング大事。\n",
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 128\n",
    "VOCAB_SIZE = len(word2index)\n",
    "TAG_SIZE = len(categories)\n",
    "# to(device)でモデルがGPU対応する\n",
    "model = LSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TAG_SIZE).to(device)\n",
    "loss_function = nn.NLLLoss()\n",
    "# SGDからAdamに変更。特に意味はなし\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "BaNbXi43YgUT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 28s 72ms/step - loss: 0.6909 - accuracy: 0.5000\n",
      "Test Loss: 0.6909476518630981\n",
      "Test Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "test_num = len(test_x)\n",
    "a = 0\n",
    "with torch.no_grad():\n",
    "    title_batch, category_batch = train2batch(test_x, test_y)\n",
    "\n",
    "    for i in range(len(title_batch)):\n",
    "        title_tensor = torch.tensor(title_batch[i], device=device)\n",
    "        category_tensor = torch.tensor(category_batch[i], device=device)\n",
    "\n",
    "        out = model(title_tensor)\n",
    "        _, predicts = torch.max(out, 1)\n",
    "        for j, ans in enumerate(category_tensor):\n",
    "            if predicts[j].item() == ans.item():\n",
    "                a += 1\n",
    "print(\"predict : \", a / test_num)\n",
    "# predict :  0.6967916854948034"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7g1evcaRpTKm"
   },
   "source": [
    "## 2つ以上の LSTM レイヤーを重ねる\n",
    "\n",
    "Keras のリカレントレイヤーには、コンストラクタの `return_sequences` 引数でコントロールされる2つのモードがあります。\n",
    "\n",
    "* それぞれのタイムステップの連続した出力のシーケンス全体（shape が `(batch_size, timesteps, output_features)` の3階テンソル）を返す。\n",
    "* それぞれの入力シーケンスの最後の出力だけ（shape が `(batch_size, output_features)` の2階テンソル）を返す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "jo1jjO3vn0jo"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "hEPV5jVGp-is"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "LeSE-YjdqAeN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "309/391 [======================>.......] - ETA: 24s - loss: 0.6921 - accuracy: 0.4997"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ceb5f272ecaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(train_dataset, epochs=10,\n\u001b[1;32m      2\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                     validation_steps=30)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=10,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "_LdwilM1qPM3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 50s 129ms/step - loss: 0.6772 - accuracy: 0.5000\n",
      "Test Loss: 0.67717444896698\n",
      "Test Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ykUKnAoqbycW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0279653]]\n"
     ]
    }
   ],
   "source": [
    "# パディングなしのサンプルテキストの推論\n",
    "\n",
    "sample_pred_text = ('The movie was not good. The animation and the graphics '\n",
    "                    'were terrible. I would not recommend this movie.')\n",
    "predictions = sample_predict(sample_pred_text, pad=False)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "2RiC-94zvdZO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16973719]]\n"
     ]
    }
   ],
   "source": [
    "# パディングありのサンプルテキストの推論\n",
    "\n",
    "sample_pred_text = ('The movie was not good. The animation and the graphics '\n",
    "                    'were terrible. I would not recommend this movie.')\n",
    "predictions = sample_predict(sample_pred_text, pad=True)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "_YYub0EDtwCu"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-41d6f4a20f1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPV3Nn9xtwFM"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xvpE3BaGw_V"
   },
   "source": [
    "[GRU レイヤー](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU)など既存のほかのレイヤーを調べてみましょう。\n",
    "\n",
    "カスタム RNN の構築に興味があるのであれば、[Keras RNN ガイド](../../guide/keras/rnn.ipynb) を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification_rnn.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "089bc7a4b5bcca8ded8f56dd6d31f99db98f335bd2546ffdf0f141ab8351be05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
