{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TnJztDZGw-n"
   },
   "source": [
    "# RNN を使ったテキスト分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z682XYsrjkY9"
   },
   "outputs": [],
   "source": [
    "# !pip install -q tf-nightly\n",
    "# import tensorflow_datasets as tfds\n",
    "# !pip3 list | grep tensorflow\n",
    "# import tensorflow as tf\n",
    "\n",
    "# !pip3 install sentencepiece\n",
    "import sentencepiece as spm\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRmMubr0jrE2"
   },
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRmMubr0jrE2"
   },
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigo\n",
      "Suugaku\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>knowledge_type</th>\n",
       "      <th>&lt;instruction/&gt;</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PRN</td>\n",
       "      <td>次の問い(問１～５)のそれぞれの単語①～④のうちから，アクセント(第一強勢)のある母音の発音...</td>\n",
       "      <td>&lt;label&gt;問１&lt;/label&gt; &lt;ansColumn id=\"A1\"&gt;1&lt;/ansC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PRN</td>\n",
       "      <td>次の問い(問１～５)のそれぞれの単語①～④のうちから，アクセント(第一強勢)のある母音の発音...</td>\n",
       "      <td>&lt;label&gt;問２&lt;/label&gt; &lt;ansColumn id=\"A2\"&gt;2&lt;/ansC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PRN</td>\n",
       "      <td>次の問い(問１～５)のそれぞれの単語①～④のうちから，アクセント(第一強勢)のある母音の発音...</td>\n",
       "      <td>&lt;label&gt;問３&lt;/label&gt; &lt;ansColumn id=\"A3\"&gt;3&lt;/ansC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PRN</td>\n",
       "      <td>次の問い(問１～５)のそれぞれの単語①～④のうちから，アクセント(第一強勢)のある母音の発音...</td>\n",
       "      <td>&lt;label&gt;問４&lt;/label&gt; &lt;ansColumn id=\"A4\"&gt;4&lt;/ansC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>PRN</td>\n",
       "      <td>次の問い(問１～５)のそれぞれの単語①～④のうちから，アクセント(第一強勢)のある母音の発音...</td>\n",
       "      <td>&lt;label&gt;問５&lt;/label&gt; &lt;ansColumn id=\"A5\"&gt;5&lt;/ansC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3028</th>\n",
       "      <td>393</td>\n",
       "      <td>MATH_IIB_VECTOR</td>\n",
       "      <td>三つのベクトル，，について …………………………① …………………………②ア，イに当てはまる...</td>\n",
       "      <td>&lt;label&gt;(2)&lt;/label&gt;  &lt;instruction&gt;&lt;formula /&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029</th>\n",
       "      <td>394</td>\n",
       "      <td>MATH_IIB_VECTOR</td>\n",
       "      <td>により，三角形ABCは正三角形である。以下，4点A，B，C，Dが，正四面体の四つの頂点になる...</td>\n",
       "      <td>&lt;label&gt;(3)&lt;/label&gt;  &lt;instruction&gt;&lt;formula&gt;(x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030</th>\n",
       "      <td>395</td>\n",
       "      <td>IC_O,IC_T,MATH_IIB_STATISTICS</td>\n",
       "      <td>0＜p＜1とする。袋の中に白球がp，赤球が1-pの割合で，全部でm個入っているものとする...</td>\n",
       "      <td>&lt;label&gt;(1)&lt;/label&gt;  &lt;instruction&gt;&lt;formula /&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3031</th>\n",
       "      <td>396</td>\n",
       "      <td>IC_O,IC_T,MATH_IIB_STATISTICS</td>\n",
       "      <td>とする。この袋の中から1個の球を取り出し袋の中へ戻すという試行を4回繰り返すとき，白球の出る...</td>\n",
       "      <td>&lt;label&gt;(2)&lt;/label&gt;  &lt;instruction&gt;&lt;formula&gt;m=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3032</th>\n",
       "      <td>397</td>\n",
       "      <td>IC_O,IC_T,MATH_IIB_STATISTICS</td>\n",
       "      <td>m=10，とする。この袋の中から同時に4個の球を取り出すとき，白球の個数を表す確率変数をYと...</td>\n",
       "      <td>&lt;label&gt;(3)&lt;/label&gt;  &lt;instruction&gt;以下では，&lt;formu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3016 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                 knowledge_type  \\\n",
       "0              0                            PRN   \n",
       "1              1                            PRN   \n",
       "2              2                            PRN   \n",
       "3              3                            PRN   \n",
       "4              4                            PRN   \n",
       "...          ...                            ...   \n",
       "3028         393                MATH_IIB_VECTOR   \n",
       "3029         394                MATH_IIB_VECTOR   \n",
       "3030         395  IC_O,IC_T,MATH_IIB_STATISTICS   \n",
       "3031         396  IC_O,IC_T,MATH_IIB_STATISTICS   \n",
       "3032         397  IC_O,IC_T,MATH_IIB_STATISTICS   \n",
       "\n",
       "                                         <instruction/>  \\\n",
       "0     次の問い(問１～５)のそれぞれの単語①～④のうちから，アクセント(第一強勢)のある母音の発音...   \n",
       "1     次の問い(問１～５)のそれぞれの単語①～④のうちから，アクセント(第一強勢)のある母音の発音...   \n",
       "2     次の問い(問１～５)のそれぞれの単語①～④のうちから，アクセント(第一強勢)のある母音の発音...   \n",
       "3     次の問い(問１～５)のそれぞれの単語①～④のうちから，アクセント(第一強勢)のある母音の発音...   \n",
       "4     次の問い(問１～５)のそれぞれの単語①～④のうちから，アクセント(第一強勢)のある母音の発音...   \n",
       "...                                                 ...   \n",
       "3028  三つのベクトル，，について …………………………① …………………………②ア，イに当てはまる...   \n",
       "3029  により，三角形ABCは正三角形である。以下，4点A，B，C，Dが，正四面体の四つの頂点になる...   \n",
       "3030    0＜p＜1とする。袋の中に白球がp，赤球が1-pの割合で，全部でm個入っているものとする...   \n",
       "3031  とする。この袋の中から1個の球を取り出し袋の中へ戻すという試行を4回繰り返すとき，白球の出る...   \n",
       "3032  m=10，とする。この袋の中から同時に4個の球を取り出すとき，白球の個数を表す確率変数をYと...   \n",
       "\n",
       "                                               contents  \n",
       "0       <label>問１</label> <ansColumn id=\"A1\">1</ansC...  \n",
       "1       <label>問２</label> <ansColumn id=\"A2\">2</ansC...  \n",
       "2       <label>問３</label> <ansColumn id=\"A3\">3</ansC...  \n",
       "3       <label>問４</label> <ansColumn id=\"A4\">4</ansC...  \n",
       "4       <label>問５</label> <ansColumn id=\"A5\">5</ansC...  \n",
       "...                                                 ...  \n",
       "3028    <label>(2)</label>  <instruction><formula />...  \n",
       "3029    <label>(3)</label>  <instruction><formula>(x...  \n",
       "3030    <label>(1)</label>  <instruction><formula />...  \n",
       "3031    <label>(2)</label>  <instruction><formula>m=...  \n",
       "3032    <label>(3)</label>  <instruction>以下では，<formu...  \n",
       "\n",
       "[3016 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbj_names = [\n",
    "#     ['Eigo']\n",
    "#     ['Suugaku']\n",
    "    ['Eigo', 'Suugaku']\n",
    "][0]\n",
    "elmnt_name = 'question'\n",
    "attr_name = 'knowledge_type'  # 'answer_type'   #\n",
    "\n",
    "df = None\n",
    "for sbj in sbj_names:\n",
    "    print(sbj)\n",
    "    attr_csv_path = f'../{sbj}_{attr_name}_ds.tsv'\n",
    "    df_tmp = pd.read_csv(attr_csv_path, delimiter='\\t')\n",
    "    df = pd.concat([df, df_tmp])\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.dropna()  # nan を削除\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRmMubr0jrE2"
   },
   "source": [
    "### Tokenize\n",
    "SentencePiece を使用。\n",
    "- タグ あり／なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SHRwRoP2nVHX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>knowledge_type</th>\n",
       "      <th>&lt;instruction/&gt;</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>270</td>\n",
       "      <td>R_QA</td>\n",
       "      <td>１～４)の空欄( 42 ～ 45 )に入れるのに最も適当なものを，それぞれ以下の①～④のうち...</td>\n",
       "      <td>&lt;label&gt;問１&lt;/label&gt;&lt;data id=\"D29\" type=\"text\"&gt;Wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>2351</td>\n",
       "      <td>DIS_W,R_ENT</td>\n",
       "      <td>次の文章を読み，下の問い（Ａ・Ｂ）に答えよ。なお，文章の左にある(1)～(6)は段落の番...</td>\n",
       "      <td>&lt;label&gt;問５&lt;/label&gt;&lt;data id=\"D48\" type=\"text\"&gt; T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>1431</td>\n",
       "      <td>DIS_S</td>\n",
       "      <td>次の問い(問１・問２)において，文章の 28 ・ 29 に入れる三つの文が，順不同で以下のA...</td>\n",
       "      <td>&lt;label&gt;問１&lt;/label&gt;  &lt;data id=\"D22\" type=\"text...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>475</td>\n",
       "      <td>DIS_S, IC_O</td>\n",
       "      <td>(配点 16)</td>\n",
       "      <td>&lt;label&gt;問３&lt;/label&gt;&lt;ansColumn id=\"A44\"&gt;44&lt;/ansCo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>532</td>\n",
       "      <td>DIS_S, R_ENT</td>\n",
       "      <td>(配点 24)</td>\n",
       "      <td>&lt;label&gt;問３&lt;/label&gt;&lt;data id=\"D43\" type=\"text\"&gt;Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 knowledge_type  \\\n",
       "270          270           R_QA   \n",
       "2351        2351    DIS_W,R_ENT   \n",
       "1431        1431          DIS_S   \n",
       "475          475    DIS_S, IC_O   \n",
       "532          532   DIS_S, R_ENT   \n",
       "\n",
       "                                         <instruction/>  \\\n",
       "270   １～４)の空欄( 42 ～ 45 )に入れるのに最も適当なものを，それぞれ以下の①～④のうち...   \n",
       "2351    次の文章を読み，下の問い（Ａ・Ｂ）に答えよ。なお，文章の左にある(1)～(6)は段落の番...   \n",
       "1431  次の問い(問１・問２)において，文章の 28 ・ 29 に入れる三つの文が，順不同で以下のA...   \n",
       "475                                            (配点 16)    \n",
       "532                                            (配点 24)    \n",
       "\n",
       "                                               contents  \n",
       "270   <label>問１</label><data id=\"D29\" type=\"text\">Wh...  \n",
       "2351  <label>問５</label><data id=\"D48\" type=\"text\"> T...  \n",
       "1431    <label>問１</label>  <data id=\"D22\" type=\"text...  \n",
       "475   <label>問３</label><ansColumn id=\"A44\">44</ansCo...  \n",
       "532   <label>問３</label><data id=\"D43\" type=\"text\">Th...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_examples, test_examples = train_test_split(\n",
    "                                    df, test_size=0.4, random_state=0)\n",
    "train_examples.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'次の一連の文章(問１・２)の中の①～③および④～⑥には，それぞれ強く発音されるべき語が一つずつある。その語を選べ。'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp = df[['<instruction/>', 'contents']]\n",
    "df_tmp['<instruction/>'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_dir = '_logs/SentencePiece'\n",
    "os.makedirs(m_dir, exist_ok=True)\n",
    "df.to_csv(f'{m_dir}/tmp.txt', sep='\\t')\n",
    "\n",
    "# arg_str = '--input={m_dir}/tmp.txt --model_prefix={m_dir}/m_user ' + '--user_defined_symbols=<sep>,<cls>' + ',<ansColumn/>,<label>' + ' --vocab_size=2000'\n",
    "# spm.SentencePieceTrainer.train(arg_str)\n",
    "\n",
    "spm.SentencePieceTrainer.train(f'--input={m_dir}/tmp.txt --model_prefix={m_dir}/m  --user_defined_symbols=<sep>,<cls>,<pad>   --vocab_size=2000')\n",
    "sp = spm.SentencePieceProcessor()  # model_file='SentencePiece/test_model.model'\n",
    "\n",
    "sp.load(f'{m_dir}/m.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁次の問い', '(', '問', '1～3)', 'の会話の', '▁17', '▁～', '▁19', '▁に入れるのに最も適当な', 'ものを', ',', 'それぞれ以下の', '1～4', 'のうちから一つずつ選', 'べ', '。']\n",
      "[70, 32, 29, 188, 609, 197, 79, 218, 169, 64, 20, 93, 59, 66, 58, 35]\n",
      "次の問い(問1～3)の会話の 17 ～ 19 に入れるのに最も適当なものを,それぞれ以下の1～4のうちから一つずつ選べ。\n"
     ]
    }
   ],
   "source": [
    "# encode: text => id\n",
    "tokenized_tokens =  sp.encode_as_pieces('次の問い(問１～３)の会話の 17 ～ 19 に入れるのに最も適当なものを，それぞれ以下の①～④のうちから一つずつ選べ。\t')\n",
    "print(tokenized_tokens)\n",
    "\n",
    "tokenized_ids = sp.encode_as_ids('次の問い(問１～３)の会話の 17 ～ 19 に入れるのに最も適当なものを，それぞれ以下の①～④のうちから一つずつ選べ。\t')\n",
    "print(tokenized_ids)\n",
    "\n",
    "decoded_text = sp.decode(tokenized_ids)\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  <label>問14</label>  <data id=\"D20\" type=\"text\"> <ansColumn id=\"A21\">21</ansColumn></data>  <choices anscol=\"A21\" comment=\"\"> <choice><cNum>①</cNum> Yes, thank you.  </choice> <choice><cNum>②</cNum> Yes, that's O.K.  </choice> <choice><cNum>③</cNum> Not at all.  </choice> <choice><cNum>④</cNum> I'd be glad to.  </choice> </choices> ['▁<', 'label', '>', '問', '14', '</', 'label', '>', '▁<', 'data', '▁id', '=', '\"', 'D', '20', '\"', '▁type', '=', '\"', 'text', '\"', '>', '▁<', 'ansColumn', '▁id', '=', '\"', 'A', '21', '\"', '>21</', 'ansColumn', '></', 'data', '>', '▁<', 'choices', '▁ans', 'col', '=', '\"', 'A', '21', '\"', '▁comment', '=\"\"', '>', '▁<', 'choice', '><', 'c', 'Num', '>1</', 'c', 'Num', '>', '▁Yes', ',', '▁than', 'k', '▁you', '.', '▁</', 'choice', '>', '▁<', 'choice', '><', 'c', 'Num', '>2</', 'c', 'Num', '>', '▁Yes', ',', '▁that', \"'\", 's', '▁', 'O', '.', 'K', '.', '▁</', 'choice', '>', '▁<', 'choice', '><', 'c', 'Num', '>3</', 'c', 'Num', '>', '▁No', 't', '▁at', '▁all', '.', '▁</', 'choice', '>', '▁<', 'choice', '><', 'c', 'Num', '>4</', 'c', 'Num', '>', '▁I', \"'\", 'd', '▁be', '▁', 'g', 'l', 'a', 'd', '▁to', '.', '▁</', 'choice', '>', '▁</', 'choices', '>']\n"
     ]
    }
   ],
   "source": [
    "example_content = df_tmp['contents'][20]\n",
    "print(example_content, sp.encode_as_pieces(example_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MDVc6UGO5Dh6"
   },
   "outputs": [],
   "source": [
    "# for index in encoded_string:\n",
    "#   print('{} ----> {}'.format(index, encoder.decode([index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlYWqhTVlUyQ"
   },
   "source": [
    "## Train 用データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VznrltNOnUc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size :  2163\n"
     ]
    }
   ],
   "source": [
    "word2index = {}\n",
    "# 系列を揃えるためのパディング文字列<pad>を追加\n",
    "# パディング文字列のIDは0とする\n",
    "word2index.update({\"<pad>\":0})\n",
    "\n",
    "for inst, cont in zip(df['<instruction/>'], df['contents']):\n",
    "#     try:\n",
    "    tokens = sp.encode_as_pieces(inst + cont)\n",
    "    for word in tokens:\n",
    "            if word in word2index: continue\n",
    "            word2index[word] = len(word2index)\n",
    "#     except TypeError:\n",
    "#         print(f'[Error] <instruction/> が nan です。')\n",
    "#         print(f'    inst : {inst}')\n",
    "#         print(f'    cont : {cont}')\n",
    "\n",
    "print(\"vocab size : \", len(word2index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DIC_O', 'DIC_O, DIS_S, R_ENT', 'DIC_O, DIS_W', 'DIC_O, DIS_W, GK', 'DIC_O, EG', 'DIC_O, EG, DIS_W', 'DIC_O, EG, GK', 'DIC_O, GK', 'DIC_O, Other', 'DIC_O, SEL', 'DIC_O,DIS_W', 'DIC_O,GK', 'DIS_C, GK', 'DIS_O', 'DIS_O, DIS_W', 'DIS_O, DIS_W, GK', 'DIS_O, GK', 'DIS_O, Other', 'DIS_S', 'DIS_S, IC_O', 'DIS_S, R_ENT', 'DIS_S, R_ENT, IC_G', 'DIS_S, R_ENT, IC_M', 'DIS_S, R_ENT, IC_O', 'DIS_S, R_ENT, IC_T', 'DIS_S, R_ENT, R_SUM', 'DIS_S,R_ENT', 'DIS_S,R_ENT,R_SUM', 'DIS_S,R_QA', 'DIS_W', 'DIS_W, GK', 'DIS_W, R_ENT', 'DIS_W, R_ENT, IC_G', 'DIS_W, R_ENT, IC_G, IC_P', 'DIS_W, R_ENT, IC_M', 'DIS_W, R_ENT, IC_O', 'DIS_W, R_ENT, IC_O, IC_P', 'DIS_W, R_ENT, IC_P', 'DIS_W, R_ENT, IC_P, IC_T', 'DIS_W, R_ENT, IC_T', 'DIS_W, R_ENT, R_SUM', 'DIS_W, R_ENT, R_SUM, IC_O', 'DIS_W, R_QA', 'DIS_W,DIC_O', 'DIS_W,EG', 'DIS_W,GK', 'DIS_W,IC_P', 'DIS_W,R_ENT', 'DIS_W,R_ENT,IC_P', 'DIS_W,R_QA', 'DIS_W,R_SUM', 'DIS_W,R_SUM,IC_T', 'EG', 'EG, ', 'EG, DIS_S', 'EG, DIS_W', 'EG, DIS_W, GK', 'EG, GK', 'EG,DIS_W', 'EG,SEL', 'FOC_1', 'FOC_1 ', 'FOC_2', 'GK,Other', 'IC_G,IC_O,MATH_IIB_STATISTICS', 'IC_G,MATH_IIB_STATISTICS', 'IC_O,IC_T,MATH_IIB_STATISTICS', 'IC_O,MATH_IA_PROBABILITY', 'IC_O,MATH_IIB_VECTOR', 'IC_T,DIS_W,R_SUM', 'IC_T,IC_G,MATH_IIB_STATISTICS', 'IC_T,IC_O,MATH_IIB_STATISTICS', 'IC_T,MATH_IIB_COMPUTER', 'IC_T,MATH_IIB_STATISTICS', 'IDM', 'IDM, DIC_O, EG', 'IDM, DIS_W', 'IDM, EG', 'IDM, EG, DIS_S', 'IDM, EG, DIS_W', 'IDM, EG, DIS_W, GK', 'IDM, EG, GK', 'IDM, SEL', 'IDM, SEL, DIS_W', 'IDM, SEL, DIS_W, GK', 'IDM, SEL, EG', 'IDM, SEL, EG, DIS_W', 'IDM, SEL, EG, DIS_W, GK', 'IDM, SEL, EG, GK', 'IDM,DIC_O', 'IDM,DIS_W', 'IDM,GK', 'IDM,SEL,EG,DIS_W', 'IDM,SEL,EG,DIS_W,IC_T', 'MATH_IA_EQ', 'MATH_IA_GEOMETRY', 'MATH_IA_PARABOLA', 'MATH_IA_PROBABILITY', 'MATH_IA_PROBABILITY,IC_O', 'MATH_IA_SET_LOGIC', 'MATH_IA_SET_LOGIC,IC_G', 'MATH_IA_SET_LOGIC,IC_G,IC_O', 'MATH_IA_SET_LOGIC,IC_G,IC_T', 'MATH_IA_SET_LOGIC,IC_T', 'MATH_IIB_CALCULUS', 'MATH_IIB_COMPUTER', 'MATH_IIB_EXPLOG', 'MATH_IIB_GEOMETRY', 'MATH_IIB_NUMSEQ', 'MATH_IIB_POLY', 'MATH_IIB_POLY,MATH_IIB_EXPLOG', 'MATH_IIB_STATISTICS', 'MATH_IIB_STATISTICS,IC_G,IC_T', 'MATH_IIB_TRIGONOMETRY', 'MATH_IIB_VECTOR', 'Other', 'Other,IC_T', 'Other,IC_T,IC_O', 'PRN', 'R_ENT', 'R_ENT, IC_G', 'R_ENT, IC_M', 'R_ENT, IC_O', 'R_ENT, IC_P', 'R_ENT, IC_T', 'R_ENT,DIS_S', 'R_ENT,DIS_W', 'R_ENT,IC_G', 'R_ENT,IC_G,IC_P', 'R_ENT,IC_O', 'R_ENT,IC_P', 'R_ENT,IC_P,DIS_S', 'R_ENT,IC_T', 'R_ENT,IC_T,IC_O', 'R_O, EG, DIS_W', 'R_QA', 'R_QA, IC_G', 'R_QA, IC_M', 'R_QA, IC_O', 'R_QA, IC_P', 'R_QA, IC_T', 'R_QA, R_ENT, R_SUM', 'R_QA, R_SUM', 'R_QA,IC_G', 'R_QA,IC_G,IC_P', 'R_QA,IC_O', 'R_QA,IC_P', 'R_QA,IC_P,DIS_S', 'R_QA,IC_P,IC_T', 'R_QA,IC_T', 'R_QA,IC_T,IC_O', 'R_RA, IC_P', 'R_SUM', 'R_SUM,IC_T', 'SEL', 'SEL, DIC_O', 'SEL, DIC_O, EG', 'SEL, DIS_W', 'SEL, EG', 'SEL, EG ', 'SEL, EG,  DIS_W', 'SEL, EG, DIS_W', 'SEL, EG, GK', 'SEL, GK', 'SEL,DIS_W', 'SEL,EG,DIS_W', 'SEL,EG,DIS_W,IDM', 'SEL,EG,DIS_W,IDM,IC_T']\n",
      "168\n"
     ]
    }
   ],
   "source": [
    "## set_dict から自動抽出する！\n",
    "# attr_name = 'knowledge_type'  # 'answer_type'\n",
    "\n",
    "categories = set()\n",
    "for sbj in sbj_names:\n",
    "    with open(f'../class_set/{sbj}-{elmnt_name}-{attr_name}.json') as f:\n",
    "        categories |= set(json.load(f))   # sbj_names = ['Eigo', ]\n",
    "\n",
    "# print(categories)\n",
    "\n",
    "categories = list(categories)\n",
    "categories.sort()    # 入れないと、クラス番号が変わってしまい、再現実験ができないので注意？\n",
    "print(categories)\n",
    "print(len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8lgLRE0z4Opm",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3016it [00:01, 2068.11it/s]\n",
      "100%|██████████| 3016/3016 [01:59<00:00, 25.34it/s]\n"
     ]
    }
   ],
   "source": [
    "## 系列の長さを揃えてバッチでまとめる\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "cat2index = {}\n",
    "for cat in categories:\n",
    "    if cat in cat2index: continue\n",
    "    cat2index[cat] = len(cat2index)\n",
    "\n",
    "def sentence2index(sentence):\n",
    "    tokens = sp.encode_as_pieces(sentence)\n",
    "    # print(tokens)\n",
    "    return [word2index[w] for w in tokens]\n",
    "\n",
    "def category2index(cat):\n",
    "    return [cat2index[cat]]\n",
    "\n",
    "index_datasets_c_xml_tmp = []\n",
    "index_datasets_category = []\n",
    "\n",
    "# 系列の長さの最大値を取得。この長さに他の系列の長さをあわせる\n",
    "max_len = 0\n",
    "for inst, cont, category in tqdm(zip(df['<instruction/>'], df['contents'], df[attr_name])):\n",
    "    index_c_xml = sentence2index(inst + cont)\n",
    "    index_category = category2index(category)\n",
    "    index_datasets_c_xml_tmp.append(index_c_xml)\n",
    "    index_datasets_category.append(index_category)\n",
    "    if max_len < len(index_c_xml):\n",
    "        max_len = len(index_c_xml)\n",
    "\n",
    "# 系列の長さを揃えるために短い系列にパディングを追加\n",
    "# 後ろパディングだと正しく学習できなかったので、前パディング\n",
    "index_datasets_c_xml = []\n",
    "for c_xml in tqdm(index_datasets_c_xml_tmp):\n",
    "    for i in range(max_len - len(c_xml)):\n",
    "        c_xml.insert(0, 0) # 前パディング\n",
    "#     c_xml.append(0)　# 後ろパディング\n",
    "    index_datasets_c_xml.append(c_xml)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(index_datasets_c_xml, index_datasets_category, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjUqGVBxGw-t"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from model_abc.LSTM_text_classify_model import LSTM_TextClassifier_ptModel\n",
    "\n",
    "# GPUを使うために必要\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LwfoBkmRYcP3"
   },
   "outputs": [],
   "source": [
    "# 単語の埋め込み次元数上げた。精度がそこそこアップ！ハイパーパラメータのチューニング大事。\n",
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 128\n",
    "VOCAB_SIZE = len(word2index)\n",
    "TAG_SIZE = len(categories)\n",
    "\n",
    "model = LSTM_TextClassifier_ptModel(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TAG_SIZE).to(device)\n",
    "\n",
    "## モデルの保存場所を準備する。\n",
    "import datetime\n",
    "dt_now = datetime.datetime.now()\n",
    "save_m_dir = os.path.join('_logs', dt_now.strftime('%Y-%m-%d_%Hh%Mm%Ss'))\n",
    "save_m_path = os.path.join(save_m_dir, 'LSTM_classifier_.pth')\n",
    "os.makedirs(save_m_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIwH3nto596k"
   },
   "source": [
    "## Experiment Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# データをバッチでまとめるための関数\n",
    "def train2batch(c_xml, category, batch_size=100):\n",
    "    c_xml_batch = []\n",
    "    category_batch = []\n",
    "    c_xml_shuffle, category_shuffle = shuffle(c_xml, category)\n",
    "    for i in range(0, len(c_xml), batch_size):\n",
    "        c_xml_batch.append(c_xml_shuffle[i:i+batch_size])\n",
    "        category_batch.append(category_shuffle[i:i+batch_size])\n",
    "    return c_xml_batch, category_batch\n",
    "\n",
    "loss_function = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/Volumes/GoogleDrive/マイドライブ/__datasets__/[CV][NLP]「センター試験xml」/annotate_img/datas/attribute/Experiment/model_abc/LSTM_text_classify_model.py:28: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  tag_scores = self.softmax(tag_space.squeeze())\n",
      "  0%|          | 0/1000 [02:23<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-99e22c04fc73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.4/envs/tensorflow2.3_py3.8/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.4/envs/tensorflow2.3_py3.8/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_loss = 1.0\n",
    "losses = []\n",
    "for epoch in tqdm(range(1000)):\n",
    "    all_loss = 0\n",
    "    title_batch, category_batch = train2batch(train_x, train_y)\n",
    "    for i in range(len(title_batch)):\n",
    "        batch_loss = 0\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        # 順伝搬させるtensorはGPUで処理させるためdevice=にGPUをセット\n",
    "        title_tensor = torch.tensor(title_batch[i], device=device)\n",
    "        # category_tensor.size() = (batch_size × 1)なので、squeeze()\n",
    "        category_tensor = torch.tensor(category_batch[i], device=device).squeeze()\n",
    "\n",
    "        out = model(title_tensor)\n",
    "\n",
    "        batch_loss = loss_function(out, category_tensor)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        all_loss += batch_loss.item()\n",
    "        if min_loss > all_loss:\n",
    "            model.save(save_m_path)\n",
    "\n",
    "    print(\"epoch\", epoch, \"\\t\" , \"loss\", all_loss)\n",
    "    if all_loss < 0.01: break\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Acc 計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "BaNbXi43YgUT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:54<00:00, 11.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict :  0.02983425414364641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_num = len(test_x)\n",
    "a = 0\n",
    "with torch.no_grad():\n",
    "    title_batch, category_batch = train2batch(test_x, test_y)\n",
    "\n",
    "    for i in tqdm(range(len(title_batch))):\n",
    "        title_tensor = torch.tensor(title_batch[i], device=device)\n",
    "        category_tensor = torch.tensor(category_batch[i], device=device)\n",
    "\n",
    "        out = model(title_tensor)\n",
    "        _, predicts = torch.max(out, 1)\n",
    "        for j, ans in enumerate(category_tensor):\n",
    "            if predicts[j].item() == ans.item():\n",
    "                a += 1\n",
    "#             else:\n",
    "#                 print(predicts[j].item(), ans.item())\n",
    "print(\"predict : \", a / test_num)\n",
    "# predict :  0.6967916854948034"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification_rnn.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "089bc7a4b5bcca8ded8f56dd6d31f99db98f335bd2546ffdf0f141ab8351be05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}