{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "0nbI5DtDGw-i"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TnJztDZGw-n"
   },
   "source": [
    "# RNN を使ったテキスト分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "z682XYsrjkY9"
   },
   "outputs": [],
   "source": [
    "# !pip install -q tf-nightly\n",
    "# import tensorflow_datasets as tfds\n",
    "# !pip3 list | grep tensorflow\n",
    "# import tensorflow as tf\n",
    "\n",
    "# !pip3 install sentencepiece\n",
    "import sentencepiece as spm\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# GPUを使うために必要\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Mp1Z7P9pYRSK"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_graphs(history, metric):\n",
    "#   plt.plot(history.history[metric])\n",
    "#   plt.plot(history.history['val_'+metric], '')\n",
    "#   plt.xlabel(\"Epochs\")\n",
    "#   plt.ylabel(metric)\n",
    "#   plt.legend([metric, 'val_'+metric])\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRmMubr0jrE2"
   },
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRmMubr0jrE2"
   },
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>&lt;instruction/&gt;</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(symbol-sentence)*2</td>\n",
       "      <td>次の問い(問１・問２)において，下線部(a)・(b)の単語のアクセント(強勢)の位置が正しい...</td>\n",
       "      <td>&lt;label&gt;問１&lt;/label&gt;  &lt;ansColumn id=\"A1\"&gt;1&lt;/ansC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(symbol-sentence)*2</td>\n",
       "      <td>次の問い(問１・問２)において，下線部(a)・(b)の単語のアクセント(強勢)の位置が正しい...</td>\n",
       "      <td>&lt;label&gt;問２&lt;/label&gt;  &lt;ansColumn id=\"A2\"&gt;2&lt;/ansC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sentence</td>\n",
       "      <td>次の会話の下線部(1)～(4)について，それぞれ以下の問い(問１～４)に示された①～④のうち...</td>\n",
       "      <td>&lt;label&gt;問１&lt;/label&gt;  &lt;ansColumn id=\"A3\"&gt;3&lt;/ansC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>sentence</td>\n",
       "      <td>次の会話の下線部(1)～(4)について，それぞれ以下の問い(問１～４)に示された①～④のうち...</td>\n",
       "      <td>&lt;label&gt;問２&lt;/label&gt;  &lt;ansColumn id=\"A4\"&gt;4&lt;/ansC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>sentence</td>\n",
       "      <td>次の会話の下線部(1)～(4)について，それぞれ以下の問い(問１～４)に示された①～④のうち...</td>\n",
       "      <td>&lt;label&gt;問３&lt;/label&gt;  &lt;ansColumn id=\"A5\"&gt;5&lt;/ansC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>978</td>\n",
       "      <td>sentence</td>\n",
       "      <td>次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なものを，それぞれ下の①～④のう...</td>\n",
       "      <td>&lt;label&gt;問２&lt;/label&gt;  &lt;data id=\"D44\" type=\"text...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>979</td>\n",
       "      <td>sentence</td>\n",
       "      <td>次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なものを，それぞれ下の①～④のう...</td>\n",
       "      <td>&lt;label&gt;問３&lt;/label&gt;  &lt;data id=\"D45\" type=\"text...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>980</td>\n",
       "      <td>sentence</td>\n",
       "      <td>次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なものを，それぞれ下の①～④のう...</td>\n",
       "      <td>&lt;label&gt;問４&lt;/label&gt;  &lt;data id=\"D46\" type=\"text...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>981</td>\n",
       "      <td>sentence</td>\n",
       "      <td>次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なものを，それぞれ下の①～④のう...</td>\n",
       "      <td>&lt;label&gt;問５&lt;/label&gt;  &lt;data id=\"D47\" type=\"text...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>982</td>\n",
       "      <td>sentence</td>\n",
       "      <td>次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なものを，それぞれ下の①～④のう...</td>\n",
       "      <td>&lt;label&gt;Ｂ&lt;/label&gt;&lt;instruction&gt;  次の  &lt;ref target...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>983 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0          answer_type  \\\n",
       "0             0  (symbol-sentence)*2   \n",
       "1             1  (symbol-sentence)*2   \n",
       "2             2             sentence   \n",
       "3             3             sentence   \n",
       "4             4             sentence   \n",
       "..          ...                  ...   \n",
       "978         978             sentence   \n",
       "979         979             sentence   \n",
       "980         980             sentence   \n",
       "981         981             sentence   \n",
       "982         982             sentence   \n",
       "\n",
       "                                        <instruction/>  \\\n",
       "0    次の問い(問１・問２)において，下線部(a)・(b)の単語のアクセント(強勢)の位置が正しい...   \n",
       "1    次の問い(問１・問２)において，下線部(a)・(b)の単語のアクセント(強勢)の位置が正しい...   \n",
       "2    次の会話の下線部(1)～(4)について，それぞれ以下の問い(問１～４)に示された①～④のうち...   \n",
       "3    次の会話の下線部(1)～(4)について，それぞれ以下の問い(問１～４)に示された①～④のうち...   \n",
       "4    次の会話の下線部(1)～(4)について，それぞれ以下の問い(問１～４)に示された①～④のうち...   \n",
       "..                                                 ...   \n",
       "978  次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なものを，それぞれ下の①～④のう...   \n",
       "979  次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なものを，それぞれ下の①～④のう...   \n",
       "980  次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なものを，それぞれ下の①～④のう...   \n",
       "981  次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なものを，それぞれ下の①～④のう...   \n",
       "982  次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なものを，それぞれ下の①～④のう...   \n",
       "\n",
       "                                              contents  \n",
       "0     <label>問１</label>  <ansColumn id=\"A1\">1</ansC...  \n",
       "1     <label>問２</label>  <ansColumn id=\"A2\">2</ansC...  \n",
       "2     <label>問１</label>  <ansColumn id=\"A3\">3</ansC...  \n",
       "3     <label>問２</label>  <ansColumn id=\"A4\">4</ansC...  \n",
       "4     <label>問３</label>  <ansColumn id=\"A5\">5</ansC...  \n",
       "..                                                 ...  \n",
       "978    <label>問２</label>  <data id=\"D44\" type=\"text...  \n",
       "979    <label>問３</label>  <data id=\"D45\" type=\"text...  \n",
       "980    <label>問４</label>  <data id=\"D46\" type=\"text...  \n",
       "981    <label>問５</label>  <data id=\"D47\" type=\"text...  \n",
       "982  <label>Ｂ</label><instruction>  次の  <ref target...  \n",
       "\n",
       "[983 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbj_name = 'Eigo'\n",
    "attr_name = 'answer_type'\n",
    "\n",
    "attr_csv_path = f'../{sbj_name}_{attr_name}_ds.tsv'\n",
    "df = pd.read_csv(attr_csv_path, delimiter='\\t')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRmMubr0jrE2"
   },
   "source": [
    "### Tokenize\n",
    "SentencePiece を使用。\n",
    "- タグ あり／なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SHRwRoP2nVHX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>&lt;instruction/&gt;</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>893</td>\n",
       "      <td>sentence</td>\n",
       "      <td>次の問い（問１～４）において，第一アクセント（第一強勢）の位置がほかの三つと異なるものを，そ...</td>\n",
       "      <td>&lt;label&gt;問２&lt;/label&gt;  &lt;ansColumn id=\"A5\"&gt;5&lt;/ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>158</td>\n",
       "      <td>sentence</td>\n",
       "      <td>次の広告に関する以下の問い(問１～３)を読み， 39 ～ 41 に入れるのに最も適当なものを...</td>\n",
       "      <td>&lt;label&gt;問２&lt;/label&gt;  &lt;data id=\"D30\" type=\"text...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>154</td>\n",
       "      <td>sentence</td>\n",
       "      <td>次の英文は，体育の授業時間数について，クラスで行われたディスカッションの一部である。文中の ...</td>\n",
       "      <td>&lt;label&gt;Ｃ&lt;/label&gt; 次&lt;instruction&gt;  の文章の &lt;ref tar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>sentence</td>\n",
       "      <td>次の問い(問１～５)に対する答えとして最も適当なものを，それぞれ以下の①～④のうちから一つず...</td>\n",
       "      <td>&lt;label&gt;Ｂ&lt;/label&gt;&lt;instruction&gt;本文の内容と合っているものを，次の...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>793</td>\n",
       "      <td>sentence</td>\n",
       "      <td>次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なものを，それぞれ下の①～④のう...</td>\n",
       "      <td>&lt;label&gt;問５&lt;/label&gt;&lt;data id=\"D44\" type=\"text\"&gt; W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 answer_type  \\\n",
       "893         893    sentence   \n",
       "158         158    sentence   \n",
       "154         154    sentence   \n",
       "40           40    sentence   \n",
       "793         793    sentence   \n",
       "\n",
       "                                        <instruction/>  \\\n",
       "893  次の問い（問１～４）において，第一アクセント（第一強勢）の位置がほかの三つと異なるものを，そ...   \n",
       "158  次の広告に関する以下の問い(問１～３)を読み， 39 ～ 41 に入れるのに最も適当なものを...   \n",
       "154  次の英文は，体育の授業時間数について，クラスで行われたディスカッションの一部である。文中の ...   \n",
       "40   次の問い(問１～５)に対する答えとして最も適当なものを，それぞれ以下の①～④のうちから一つず...   \n",
       "793  次の問い（問１～５）の 47 ～ 51 に入れるのに最も適当なものを，それぞれ下の①～④のう...   \n",
       "\n",
       "                                              contents  \n",
       "893    <label>問２</label>  <ansColumn id=\"A5\">5</ans...  \n",
       "158    <label>問２</label>  <data id=\"D30\" type=\"text...  \n",
       "154  <label>Ｃ</label> 次<instruction>  の文章の <ref tar...  \n",
       "40   <label>Ｂ</label><instruction>本文の内容と合っているものを，次の...  \n",
       "793  <label>問５</label><data id=\"D44\" type=\"text\"> W...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_examples, test_examples = train_test_split(\n",
    "                                    df, test_size=0.2, random_state=0)\n",
    "train_examples.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'次の問い(問１～10)の 7 ～ 16 に入れるのに最も適当なものを，それぞれ以下の①～④のうちから一つずつ選べ。'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp = df[['<instruction/>', 'contents']]\n",
    "df_tmp['<instruction/>'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_dir = 'model/SentencePiece'\n",
    "os.makedirs(m_dir, exist_ok=True)\n",
    "df.to_csv(f'{m_dir}/tmp.txt', sep='\\t')\n",
    "\n",
    "# arg_str = '--input={m_dir}/tmp.txt --model_prefix={m_dir}/m_user ' + '--user_defined_symbols=<sep>,<cls>' + ',<ansColumn/>,<label>' + ' --vocab_size=2000'\n",
    "# spm.SentencePieceTrainer.train(arg_str)\n",
    "\n",
    "spm.SentencePieceTrainer.train(f'--input={m_dir}/tmp.txt --model_prefix={m_dir}/m  --user_defined_symbols=<sep>,<cls>,<pad>   --vocab_size=2000')\n",
    "sp = spm.SentencePieceProcessor()  # model_file='SentencePiece/test_model.model'\n",
    "\n",
    "sp.load(f'{m_dir}/m.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁次の', '問', 'い', '(', '問', '1～3)', 'の会話の', '▁17', '▁～', '▁19', '▁に入れるのに最も適当な', 'ものを', ',', 'それぞれ以下の', '1～4', 'のうちから一つずつ選', 'べ', '。']\n",
      "[68, 23, 52, 34, 23, 105, 299, 138, 85, 300, 86, 70, 19, 148, 61, 63, 57, 37]\n",
      "次の問い(問1～3)の会話の 17 ～ 19 に入れるのに最も適当なものを,それぞれ以下の1～4のうちから一つずつ選べ。\n"
     ]
    }
   ],
   "source": [
    "# encode: text => id\n",
    "tokenized_tokens =  sp.encode_as_pieces('次の問い(問１～３)の会話の 17 ～ 19 に入れるのに最も適当なものを，それぞれ以下の①～④のうちから一つずつ選べ。\t')\n",
    "print(tokenized_tokens)\n",
    "\n",
    "tokenized_ids = sp.encode_as_ids('次の問い(問１～３)の会話の 17 ～ 19 に入れるのに最も適当なものを，それぞれ以下の①～④のうちから一つずつ選べ。\t')\n",
    "print(tokenized_ids)\n",
    "\n",
    "decoded_text = sp.decode(tokenized_ids)\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<label>問２</label><data id=\"D20\" type=\"text\">New information about diet<blank id=\"B4\" />  <ansColumn id=\"A22\">22</ansColumn>  <blank id=\"B5\" />  <ansColumn id=\"A23\">23</ansColumn>  <blank id=\"B6\" /> think is incorrect.</data><choices anscol=\"A22 A23\" comment=\"\"><choice ansnum=\"1\">  <cNum>①</cNum> us</choice><choice ansnum=\"2\">  <cNum>②</cNum> many people</choice><choice ansnum=\"3\">  <cNum>③</cNum> shows</choice><choice ansnum=\"4\">  <cNum>④</cNum> what</choice><choice ansnum=\"5\">  <cNum>⑤</cNum> that</choice> </choices>   ['▁<', 'lab', 'el', '>', '問', '2</', 'lab', 'el', '><', 'data', '▁id', '=', '\"', 'D', '20', '\"', '▁type', '=', '\"', 'text', '\"', '>', 'New', '▁information', '▁about', '▁di', 'et', '<', 'blank', '▁id', '=', '\"', 'B', '4', '\"', '▁/>', '▁<', 'ansColumn', '▁id', '=', '\"', 'A', '2', '2', '\"', '>', '2', '2</', 'ansColumn', '>', '▁<', 'blank', '▁id', '=', '\"', 'B', '5', '\"', '▁/>', '▁<', 'ansColumn', '▁id', '=', '\"', 'A', '2', '3', '\"', '>', '2', '3</', 'ansColumn', '>', '▁<', 'blank', '▁id', '=', '\"', 'B', '6', '\"', '▁/>', '▁think', '▁is', '▁in', 'c', 'or', 're', 'c', 't', '.</', 'data', '><', 'choices', '▁ans', 'col', '=', '\"', 'A', '2', '2', '▁A', '2', '3', '\"', '▁comment', '=\"\"', '><', 'choice', '▁ans', 'num', '=', '\"', '1', '\"', '>', '▁<', 'c', 'Nu', 'm', '>1</', 'c', 'Nu', 'm', '>', '▁us', '</', 'choice', '><', 'choice', '▁ans', 'num', '=', '\"', '2', '\"', '>', '▁<', 'c', 'Nu', 'm', '>2</', 'c', 'Nu', 'm', '>', '▁', 'many', '▁people', '</', 'choice', '><', 'choice', '▁ans', 'num', '=', '\"', '3', '\"', '>', '▁<', 'c', 'Nu', 'm', '>3</', 'c', 'Nu', 'm', '>', '▁show', 's', '</', 'choice', '><', 'choice', '▁ans', 'num', '=', '\"', '4', '\"', '>', '▁<', 'c', 'Nu', 'm', '>4</', 'c', 'Nu', 'm', '>', '▁what', '</', 'choice', '><', 'choice', '▁ans', 'num', '=', '\"', '5', '\"', '>', '▁<', 'c', 'Nu', 'm', '>5</', 'c', 'Nu', 'm', '>', '▁that', '</', 'choice', '>', '▁</', 'choices', '>']\n"
     ]
    }
   ],
   "source": [
    "example_content = df_tmp['contents'][20]\n",
    "print(example_content, sp.encode_as_pieces(example_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "MDVc6UGO5Dh6"
   },
   "outputs": [],
   "source": [
    "# for index in encoded_string:\n",
    "#   print('{} ----> {}'.format(index, encoder.decode([index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlYWqhTVlUyQ"
   },
   "source": [
    "## 訓練用データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VznrltNOnUc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size :  1911\n"
     ]
    }
   ],
   "source": [
    "word2index = {}\n",
    "# 系列を揃えるためのパディング文字列<pad>を追加\n",
    "# パディング文字列のIDは0とする\n",
    "word2index.update({\"<pad>\":0})\n",
    "\n",
    "for inst, cont in zip(df['<instruction/>'], df['contents']):\n",
    "    tokens = sp.encode_as_pieces(inst + cont)\n",
    "    for word in tokens:\n",
    "        if word in word2index: continue\n",
    "        word2index[word] = len(word2index)\n",
    "print(\"vocab size : \", len(word2index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    'sentence', \n",
    "    'term_person', 'term_location', 'term_time', 'term_other',\n",
    "    'referenceSymbol',\n",
    "    'image_graph', 'image_photo', 'image_map', 'image_table', 'image_other',\n",
    "    'formula', \n",
    "    'orthography',\n",
    "    'other',\n",
    "    # 組み合わせ系（仮追加）\n",
    "    '(symbol-sentence)*2', '(symbol-sentence)*3', '(symbol-sentence)*4', '(symbol-term_location)*3', '(symbol-term_other)*3', '(symbol-term_other)*3',\n",
    "    '(symbol-symbol)*4',\n",
    "    '(term_location-term_location-term_location)', 'term_location-term_location-term_location-term_location',\n",
    "    '(term_location-term_location-term_location)', '(term_location-term_location-term_location)',\n",
    "    '(term_other-term_other-term_other)',\n",
    "    'sentence-sentence',\n",
    "    'symbol-symbol-symbol',\n",
    "    'o(symbol-symbol-symbol-symbol)',\n",
    "    'o(symbol-symbol-symbol)',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fv2DVb2m4Opl"
   },
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8lgLRE0z4Opm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 系列の長さを揃えてバッチでまとめる\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "cat2index = {}\n",
    "for cat in categories:\n",
    "    if cat in cat2index: continue\n",
    "    cat2index[cat] = len(cat2index)\n",
    "\n",
    "def sentence2index(sentence):\n",
    "    tokens = sp.encode_as_pieces(sentence)\n",
    "    # print(tokens)\n",
    "    return [word2index[w] for w in tokens]\n",
    "\n",
    "def category2index(cat):\n",
    "    return [cat2index[cat]]\n",
    "\n",
    "index_datasets_c_xml_tmp = []\n",
    "index_datasets_category = []\n",
    "\n",
    "# 系列の長さの最大値を取得。この長さに他の系列の長さをあわせる\n",
    "max_len = 0\n",
    "for inst, cont, category in zip(df['<instruction/>'], df['contents'], df['answer_type']):\n",
    "  index_c_xml = sentence2index(inst + cont)\n",
    "  index_category = category2index(category)\n",
    "  index_datasets_c_xml_tmp.append(index_c_xml)\n",
    "  index_datasets_category.append(index_category)\n",
    "  if max_len < len(index_c_xml):\n",
    "    max_len = len(index_c_xml)\n",
    "\n",
    "# 系列の長さを揃えるために短い系列にパディングを追加\n",
    "# 後ろパディングだと正しく学習できなかったので、前パディング\n",
    "index_datasets_c_xml = []\n",
    "for c_xml in index_datasets_c_xml_tmp:\n",
    "  for i in range(max_len - len(c_xml)):\n",
    "    c_xml.insert(0, 0) # 前パディング\n",
    "#     c_xml.append(0)　# 後ろパディング\n",
    "  index_datasets_c_xml.append(c_xml)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(index_datasets_c_xml, index_datasets_category, train_size=0.7)\n",
    "\n",
    "# データをバッチでまとめるための関数\n",
    "def train2batch(c_xml, category, batch_size=100):\n",
    "  c_xml_batch = []\n",
    "  category_batch = []\n",
    "  c_xml_shuffle, category_shuffle = shuffle(c_xml, category)\n",
    "  for i in range(0, len(c_xml), batch_size):\n",
    "    c_xml_batch.append(c_xml_shuffle[i:i+batch_size])\n",
    "    category_batch.append(category_shuffle[i:i+batch_size])\n",
    "  return c_xml_batch, category_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjUqGVBxGw-t"
   },
   "source": [
    "## モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LwfoBkmRYcP3"
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # <pad>の単語IDが0なので、padding_idx=0としている\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        # batch_first=Trueが大事！\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        #embeds.size() = (batch_size × len(sentence) × embedding_dim)\n",
    "        _, lstm_out = self.lstm(embeds)\n",
    "        # lstm_out[0].size() = (1 × batch_size × hidden_dim)\n",
    "        tag_space = self.hidden2tag(lstm_out[0])\n",
    "        # tag_space.size() = (1 × batch_size × tagset_size)\n",
    "\n",
    "        # (batch_size × tagset_size)にするためにsqueeze()する\n",
    "        tag_scores = self.softmax(tag_space.squeeze())\n",
    "        # tag_scores.size() = (batch_size × tagset_size)\n",
    "\n",
    "        return tag_scores\n",
    "\n",
    "# 単語の埋め込み次元数上げた。精度がそこそこアップ！ハイパーパラメータのチューニング大事。\n",
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 128\n",
    "VOCAB_SIZE = len(word2index)\n",
    "TAG_SIZE = len(categories)\n",
    "# to(device)でモデルがGPU対応する\n",
    "model = LSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TAG_SIZE).to(device)\n",
    "loss_function = nn.NLLLoss()\n",
    "# SGDからAdamに変更。特に意味はなし\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIwH3nto596k"
   },
   "source": [
    "## モデルの訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 \t loss 18.353562116622925\n",
      "epoch 1 \t loss 8.046313345432281\n",
      "epoch 2 \t loss 6.411768734455109\n",
      "epoch 3 \t loss 6.1079630851745605\n",
      "epoch 4 \t loss 5.906205236911774\n",
      "epoch 5 \t loss 5.816978633403778\n",
      "epoch 6 \t loss 5.777347922325134\n",
      "epoch 7 \t loss 5.721486747264862\n",
      "epoch 8 \t loss 5.629653513431549\n",
      "epoch 9 \t loss 5.535482347011566\n",
      "epoch 10 \t loss 5.455973744392395\n",
      "epoch 11 \t loss 5.290098488330841\n",
      "epoch 12 \t loss 5.068092346191406\n",
      "epoch 13 \t loss 4.7663169503211975\n",
      "epoch 14 \t loss 4.224766790866852\n",
      "epoch 15 \t loss 3.7899158000946045\n",
      "epoch 16 \t loss 3.5029635429382324\n",
      "epoch 17 \t loss 3.160395711660385\n",
      "epoch 18 \t loss 3.0177665054798126\n",
      "epoch 19 \t loss 2.7753783762454987\n",
      "epoch 20 \t loss 2.4795882552862167\n",
      "epoch 21 \t loss 2.1993174701929092\n",
      "epoch 22 \t loss 2.0467266142368317\n",
      "epoch 23 \t loss 1.85104900598526\n",
      "epoch 24 \t loss 1.5724025443196297\n",
      "epoch 25 \t loss 1.4392117112874985\n",
      "epoch 26 \t loss 1.372746929526329\n",
      "epoch 27 \t loss 1.242957390844822\n",
      "epoch 28 \t loss 1.079236850142479\n",
      "epoch 29 \t loss 0.9924646653234959\n",
      "epoch 30 \t loss 0.8871841728687286\n",
      "epoch 31 \t loss 0.8145831227302551\n",
      "epoch 32 \t loss 0.6958238519728184\n",
      "epoch 33 \t loss 0.946124717593193\n",
      "epoch 34 \t loss 0.80819121748209\n",
      "epoch 35 \t loss 0.6709140315651894\n",
      "epoch 36 \t loss 0.5727086663246155\n",
      "epoch 37 \t loss 0.5024823322892189\n",
      "epoch 38 \t loss 0.44376990757882595\n",
      "epoch 39 \t loss 0.40496140345931053\n",
      "epoch 40 \t loss 0.3670508358627558\n",
      "epoch 41 \t loss 0.32662439346313477\n",
      "epoch 42 \t loss 0.2952745920047164\n",
      "epoch 43 \t loss 0.2697832975536585\n",
      "epoch 44 \t loss 0.24120903387665749\n",
      "epoch 45 \t loss 0.2199822636321187\n",
      "epoch 46 \t loss 0.2033570036292076\n",
      "epoch 47 \t loss 0.18495638109743595\n",
      "epoch 48 \t loss 0.16854913160204887\n",
      "epoch 49 \t loss 0.15886602643877268\n",
      "epoch 50 \t loss 0.14301712531596422\n",
      "epoch 51 \t loss 0.13461523689329624\n",
      "epoch 52 \t loss 0.12574867997318506\n",
      "epoch 53 \t loss 0.11614667414687574\n",
      "epoch 54 \t loss 0.1090784939005971\n",
      "epoch 55 \t loss 0.10036800894886255\n",
      "epoch 56 \t loss 0.09436599165201187\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(100):\n",
    "    all_loss = 0\n",
    "    title_batch, category_batch = train2batch(train_x, train_y)\n",
    "    for i in range(len(title_batch)):\n",
    "        batch_loss = 0\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        # 順伝搬させるtensorはGPUで処理させるためdevice=にGPUをセット\n",
    "        title_tensor = torch.tensor(title_batch[i], device=device)\n",
    "        # category_tensor.size() = (batch_size × 1)なので、squeeze()\n",
    "        category_tensor = torch.tensor(category_batch[i], device=device).squeeze()\n",
    "\n",
    "        out = model(title_tensor)\n",
    "\n",
    "        batch_loss = loss_function(out, category_tensor)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        all_loss += batch_loss.item()\n",
    "    print(\"epoch\", epoch, \"\\t\" , \"loss\", all_loss)\n",
    "    if all_loss < 0.1: break\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BaNbXi43YgUT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict :  0.864406779661017\n"
     ]
    }
   ],
   "source": [
    "test_num = len(test_x)\n",
    "a = 0\n",
    "with torch.no_grad():\n",
    "    title_batch, category_batch = train2batch(test_x, test_y)\n",
    "\n",
    "    for i in range(len(title_batch)):\n",
    "        title_tensor = torch.tensor(title_batch[i], device=device)\n",
    "        category_tensor = torch.tensor(category_batch[i], device=device)\n",
    "\n",
    "        out = model(title_tensor)\n",
    "        _, predicts = torch.max(out, 1)\n",
    "        for j, ans in enumerate(category_tensor):\n",
    "            if predicts[j].item() == ans.item():\n",
    "                a += 1\n",
    "print(\"predict : \", a / test_num)\n",
    "# predict :  0.6967916854948034"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7g1evcaRpTKm"
   },
   "source": [
    "## 2つ以上の LSTM レイヤーを重ねる\n",
    "\n",
    "Keras のリカレントレイヤーには、コンストラクタの `return_sequences` 引数でコントロールされる2つのモードがあります。\n",
    "\n",
    "* それぞれのタイムステップの連続した出力のシーケンス全体（shape が `(batch_size, timesteps, output_features)` の3階テンソル）を返す。\n",
    "* それぞれの入力シーケンスの最後の出力だけ（shape が `(batch_size, output_features)` の2階テンソル）を返す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jo1jjO3vn0jo"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4709297e8b57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = tf.keras.Sequential([\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEPV5jVGp-is"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LeSE-YjdqAeN"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=10,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LdwilM1qPM3"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykUKnAoqbycW"
   },
   "outputs": [],
   "source": [
    "# パディングなしのサンプルテキストの推論\n",
    "\n",
    "sample_pred_text = ('The movie was not good. The animation and the graphics '\n",
    "                    'were terrible. I would not recommend this movie.')\n",
    "predictions = sample_predict(sample_pred_text, pad=False)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2RiC-94zvdZO"
   },
   "outputs": [],
   "source": [
    "# パディングありのサンプルテキストの推論\n",
    "\n",
    "sample_pred_text = ('The movie was not good. The animation and the graphics '\n",
    "                    'were terrible. I would not recommend this movie.')\n",
    "predictions = sample_predict(sample_pred_text, pad=True)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YYub0EDtwCu"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPV3Nn9xtwFM"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xvpE3BaGw_V"
   },
   "source": [
    "[GRU レイヤー](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU)など既存のほかのレイヤーを調べてみましょう。\n",
    "\n",
    "カスタム RNN の構築に興味があるのであれば、[Keras RNN ガイド](../../guide/keras/rnn.ipynb) を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification_rnn.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "089bc7a4b5bcca8ded8f56dd6d31f99db98f335bd2546ffdf0f141ab8351be05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
